### Введение

    Мне всегда было интересно можно ли собирать домашнии компьютеры не только для игр или для работы, а для чего-то еще ?
    Этим что-то еще стало AI и получится ли использовать этот комп
     для AI(Artificial intelligence) в частности для ML.
    Я постапвил перед собой задачу выяснить это.
    Постораюсь использовать  несколько компьютеров собранных в разное время и результаты которые они выдадут.
    Во всех вариантах буду запускать скрипт на Python, который должнет выдовать результаты для разного количества входных данных:
    samples = [50_000, 100_000, 250_000, 500_000, 750_000, 1_000_000]
    и строить, на основнии этого график, отдельно для CPU и GPU.
    В дальнейшем надеюсь сравнить результаты разных копьютеров и на сколько процентов произошел прирост в производительности.
    Конечно возможны ошибки и все это относительно, но все равно, все это очень интересно :)
    Результат работы скрипта: Artificial intelligence.ipynb сохраню в виде csv-файла и поcтроим график.

* FirstPC:
  * Intel Core i7-2600CPU - 2011 года - подойдет(встроенное графическое ядро HD Graphics 2000 с максимальной частотой 1350 МГц)
  * Nvidia GeForce GTX 750 Ti - 4GB - 2014 года - для обучения, не подойдет
  * DDR3 - 24GB
* SecondPC:
  * AMD Ryzen5 3600 - 2018 года - подойдет
  * ASUS DUAL RTX 3050 6 GB - 2022 года - подойдет
  * DDR4 - 32GB

```txt
| Устройство       | Поддержка GPU в XGBoost  | Практическая польза |
|------------------|--------------------------|----------------------|
| GTX 750 Ti       | ❌ нет (устарела)        | Замедление           |
| RTX 3050         | ✅ да                    | Ускорение в 2–10×     |
| CPU (i7-2600)    | ✅                       | Может быть быстрее на малых выборках |

```
***Вывод:
CPU на PC2 быстрее почти в 2 раза, особенно на больших выборках.
GPU: на миллион строк RTX 3050 обучает модель в 3.5 раза быстрее, чем старенькая GTX 750 Ti.***

Источник: https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/blob/main/task01/Result/xgb_fit_comparison.png
![ИИ](https://private-user-images.githubusercontent.com/121765005/440842597-c13f3a2f-de47-4620-81e1-138dafdf431a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDQ1NjIsIm5iZiI6MTc0NjU0NDI2MiwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODQyNTk3LWMxM2YzYTJmLWRlNDctNDYyMC04MWUxLTEzOGRhZmRmNDMxYS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNTExMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YTZhOGJmMzBlMmI3YzY0NjMwY2VkODFjZWU0YzIzNDZlYWVkMTY2N2RmMTI0Y2UwYzcxZDhjNWRhMDFlODEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.4M--w6dyE4uIXpau__1bt6hzQZjT5JozQAclkJZ4pIY "выбор железа для ИИ")

```text
Какими минимальными характеристиками должен обладать 
домашний компьютер 
для реализации Машинного обучения с учителем 
с использованием простой линейной или логистической регрессии, 
для прогнозирования некоторых значений, полученных в результате эксперимента?
```

Результат:

1. Минимальные аппаратные характеристики:
    * 1.1 Процессор (CPU)
    Минимум: 4-ядерный, например, Intel Core i5 или AMD Ryzen 5 (модели начиная с 2017 года).

        Рекомендация: Тактовая частота ≥ 2.5 ГГц, поддержка AVX (для ускорения NumPy и Scikit-learn).

        Зачем: Обработка данных (особенно при подготовке и обучении моделей), если нет GPU — модели обучаются на CPU.
    * 1.2 Оперативная память (RAM)
        Минимум: 8 ГБ.

        Рекомендация: 16 ГБ — если работать с большими датафреймами (более 1 млн строк).

        Зачем: Хранение набора данных, промежуточных результатов, моделей.
    * 1.3 Графический процессор (GPU)
        Минимум: не требуется, если не используешь нейросети или большие тензоры (например, TensorFlow или PyTorch).

        Рекомендация (если использовать нейросети):

        NVIDIA с поддержкой CUDA (например, GTX 1660, RTX 2060+)

        VRAM: ≥ 4 ГБ.

        Зачем: Ускорение обучения нейросетей; для классической регрессии (линейной, дерева решений и т.д.) — не нужен.

2. Оценка и расчёт требований (приблизительно):
    * 2.1 Формула оценки объёма RAM:
        * RAM_needed ≈ size_of_dataset_in_memory × 3

    Пример: если CSV весит 500 МБ, то в pandas он займёт ~1.5 ГБ RAM.

    Нужно минимум втрое больше RAM, чем размер вашего DataFrame, чтобы комфортно обучать модель.

    * Формула для CPU нагрузки:
        * Training_time ∝ dataset_size × model_complexity / processing_power - чем меньше результат при больших входных данных, тем быстрее обучение.Training_time - это не само время в сек, а некоторое значение пропорциональное сек: Training_time_per_sec (в секундах) ≈ K × Training_time.
        Где:
        * dataset_size — количество примеров в обучающем наборе (в мегабайтах, строках или признаках),

        * model_complexity — условная метрика, зависящая от количества признаков, глубины модели, регуляризации и т.п.,

        * processing_power ≈ CPU_cores × frequency (GHz) × IPC.
            * (instructions per cycle — зависят от архитектуры).

    ```txt
    Допустим у нас:
        * 500 000 строк (объектов),
        * 20 признаков на строку,
        → Всего:
            500,000 × 20 = 10,000,000 чисел

    Размер одного числа
    Обычно данные для обучения представлены как:
    float64 (в numpy, pandas по умолчанию): 8 байт на число,
    или float32: 4 байта (меньше, но менее точное).
    float64:
    10,000,000 чисел × 8 байт = 80,000,000 байт = 80 MB(76.2939)
    float32:
    10,000,000 × 4 байта = 40,000,000 байт = 40 MB(38.147)

    ```

    ```txt
     Пример 1: Простая линейная регрессия на ноутбуке:
        Условия:
            * Dataset: 100 000 строк × 10 признаков (примерно 8 MB).
            * Модель: обычная линейная регрессия (model_complexity ≈ 1).
            * Процессор: 4 ядра × 2.5 GHz × IPC ≈ 1.2 (ипично для старых ноутбуков).
            * Обработка чисел — только на CPU.

            processing_power = 4 × 2.5 × 1.2 = 12
            Training_time ∝ 100 000 × 10 / 12 ≈ 83 333 условных единиц
    
    ```

    ```txt
    Пример 2: Градиентный бустинг на современном ПК:
        Условия:
            * Dataset: 1 000 000 строк × 50 признаков (примерно 400 MB).
            * Модель: XGBoost 
            (model_complexity ≈ 10–20 в условных единицах).
            * Процессор: 8 ядер × 3.6 GHz × IPC ≈ 1.5.
            * Поддержка многопоточности.

            processing_power = 8 × 3.6 × 1.5 = 43.2
            Training_time ∝ 1 000 000 × 50 × 15 / 43.2 ≈ 17 361 111 условных единиц
    ```

3. Пример минимальной конфигурации:

```txt
* Компонент   |            Минимум          |        Рекомендуется
* CPU         |Intel i5-7500 / Ryzen 5 1600 |   Intel i5-12400 / Ryzen 5 5600
* RAM         |      8 ГБ                   |           16 ГБ
* GPU         |  — (необязательно)          |NVIDIA GTX 1660 / RTX 3060 (если нейросети)


```

### DZ1

```txt
Урок 1. Искусственный интеллект. Обзор

I) Выберите один из инструментов искусственного интеллекта. 
Узнайте больше об этом инструменте, его развитии и возможных будущих разработках.

II) Определите интересующую вас отрасль (например, здравоохранение, финансы, образование или развлечения) и изучите, 
как инструмент ИИ используется в этой отрасли в настоящее время. 

III) Опишите преимущества, которые этот инструмент дает отрасли, и любые потенциальные проблемы.

Поразмышляйте об этических последствиях использования инструментов ИИ в выбранной отрасли. 

Обсудите потенциальные меры, которые могут быть приняты для решения этих этических проблем.

Напишите отчет с кратким изложением ваших выводов. Отчет должен быть объемом 3-4 страницы (около 1500 слов) 
и включать ссылки на достоверные источники.
Пожалуйста, убедитесь, что в вашем отчете есть введение, 
подробный анализ и продуманное заключение.

```
Ответ:
Один из вариантов применения ИИ в авиации.
I. - II.

1. Автоматизация полета
```txt
    Современные самолеты оснащены автопилотами, которые используют алгоритмы ИИ для управления полетом. Эти системы могут выполнять основные функции, такие как:
    * Поддержание курса и высоты: автопилот может автоматически поддерживать заданный маршрут и высоту, что снижает нагрузку на пилотов, особенно на длинных рейсах.
    * Реализация сложных маневров: в некоторых ситуациях автопилот может выполнять сложные маневры, такие как заход на посадку или взлет в условиях ограниченной видимости.
    * Оптимизация маршрута: ИИ может анализировать погодные условия, трафик и другие данные, чтобы предложить наилучший маршрут, минимизируя задержки и расход топлива.
```

2. Системы помощи пилотам (EFIS и EICAS)
```txt
    Современные авиационные системы, такие как EFIS (Electronic Flight Instrument System) и EICAS (Engine Indication and Crew Alerting System), используют ИИ для улучшения работы пилотов:
    * Предсказание и предотвращение ошибок: системы могут предупреждать пилота о возможных ошибках, например, при неправильных действиях или выходе за пределы допустимых значений.
    * Мониторинг состояния самолета: ИИ анализирует данные с различных датчиков (например, температуры, давления, скорости) и помогает пилотам выявлять неисправности до того, как они станут критическими.
```
3. Улучшение безопасности порлета
```txt
ИИ помогает повысить безопасность полетов с помощью таких технологий:
* Предсказание и предотвращение аварийных ситуаций: системы ИИ могут анализировать данные в реальном времени и предупреждать пилотов о потенциальных угрозах, таких как столкновение с другими воздушными судами, турбуленция или погодные аномалии.
* Автоматическая диагностика: ИИ может отслеживать техническое состояние самолета и предсказать возможные поломки, что позволяет пилотам и техническому персоналу заранее принимать меры.

```
4. Обучение и тренировка пилотов
```txt
ИИ используется в тренажерах для подготовки пилотов:
* Виртуальные тренажеры: с помощью ИИ создаются более реалистичные тренажеры для обучения пилотов, которые могут моделировать различные аварийные ситуации и непредсказуемые обстоятельства.
* Реальные сценарии: системы ИИ могут моделировать погодные условия, технические неисправности и другие факторы, что помогает подготовить пилотов к экстренным ситуациям.
```
5. Предсказание и предотвращение усталости пилотов
```txt
Усталость пилотов — одна из ключевых причин авиационных происшествий. ИИ помогает бороться с этой проблемой:
* Мониторинг состояния пилота: с помощью биометрических датчиков и ИИ анализируются физиологические показатели пилота (например, частота сердечных сокращений), чтобы выявить признаки усталости или стресса.
* Рекомендации по отдыху: на основе анализа данных ИИ может предложить пилоту перерыв или смену, если система определяет, что его способности к управлению самолетом могут быть снижены из-за усталости.
```
Дополнение, еще недавно это было невозможно:

6. В современной гражданской авиации уже существуют самолёты и системы, которые могут самостоятельно взлетать, приземляться и пилотировать в условиях плохих метеоусловий, включая грозы. **Однако стоит отметить, что полностью автономные самолёты, которые не требуют вмешательства человека, пока что находятся на стадии разработки.** Тем не менее, уже сегодня используются передовые технологии для автоматизации этих процессов с помощью искусственного интеллекта (ИИ) и других высокотехнологичных систем.

7. Автономные взлеты и посадки.

Современные самолёты уже оснащены автопилотами, которые могут самостоятельно выполнять сложные манёвры, такие как взлет и посадка, особенно в плохих метеоусловиях. В частности, автопилоты с низким уровнем видимости позволяют самолёту совершать посадки при ограниченной видимости (например, в условиях густого тумана или дождя). Такие системы основываются на следующих технологиях:

* Системы ILS (Instrument Landing System): Это система посадки, основанная на радиочастотных сигналах, которые помогают самолету точно определить местоположение относительно полосы. Некоторые самолёты могут выполнять посадку с использованием ILS в условиях видимости менее 75 метров, что делает возможными посадки в условиях тумана или гроз.

* Системы автопилота третьего и четвертого уровней: Эти системы могут полностью автоматизировать процесс посадки, включая взлет, полет на маршруте и посадку. Например, Boeing 787 Dreamliner и Airbus A350 оснащены такими системами, которые могут работать в плохих погодных условиях.

8. Искусственный интеллект и пилотирование в экстремальных погодных условиях
ИИ активно используется для улучшения работы автоматических систем в экстремальных условиях. Например:

* Моделирование и прогнозирование погоды: ИИ помогает прогнозировать и моделировать погодные условия на маршруте, включая грозы, сильный ветер и турбуленцию. Это позволяет автопилоту на основе данных о метеоусловиях заранее подстраивать траекторию полета и рекомендовать пилотам оптимальные действия.

* Автономные системы на базе ИИ для пилотирования в условиях турбуленции и гроз: Современные самолёты оснащены системами, которые позволяют уменьшать влияние турбуленции. ИИ может анализировать данные с датчиков и систем на борту, такие как скорость и направление ветра, давление и температуру, чтобы прогнозировать и корректировать поведение самолёта.

9. Примеры автономных и частично автономных систем в авиации:
* Boeing 737 MAX: Эта модель оснащена системой, которая автоматически корректирует траекторию полёта в случае обнаружения сильных турбуленций или плохих погодных условий. Хотя в данном случае решение о действиях остаётся за пилотом, системы автопилота помогают значительно снизить нагрузку.

* Airbus A350: Эта модель имеет автопилот, который может быть использован для взлёта и посадки в условиях низкой видимости и плохих погодных условий. Автопилот также помогает в управлении полётом при сильной турбуленции и грозах.

* Самолёты с технологиями автономного пилотирования: Например, компания Xwing разрабатывает технологию автономного пилотирования для небольших самолётов, которые могут выполнять рейсы в условиях низкой видимости или даже без человеческого вмешательства.




III. 

1. Преимущества использования ИИ в пилотировании самолетов:
* Снижение человеческого фактора: ИИ помогает минимизировать ошибки, связанные с усталостью, стрессом или недочетами пилота.
* Увеличение эффективности: автоматизация позволяет уменьшить рабочую нагрузку пилота, снизить вероятность ошибок и повысить точность выполнения маневров.
* Повышение безопасности: ИИ может предупреждать пилота о потенциальных угрозах и давать рекомендации для предотвращения аварийных ситуаций. 

2. Потенциальные проблемы:
* Зависимость от технологий: полная автоматизация может привести к тому, что пилоты будут терять навыки ручного пилотирования, что важно в экстренных ситуациях.
* Надежность и сбои: сбой в системе ИИ или неполадки с сенсорами могут привести к ошибочным рекомендациям или действиям, что в свою очередь повысит риски.
* Этические вопросы: кто несет ответственность за ошибки, если система ИИ принимает неправильное решение в экстренной ситуации?

Таким образом, ИИ в авиации играет важную роль в улучшении безопасности, эффективности и комфорта полетов, но при этом требует внимательного контроля и надежности технологий для обеспечения их безопасного использования.


3. Будущее автономной авиации:

Разработки в области полностью автономных самолётов активно продолжаются, и большинство крупных авиастроителей, таких как Airbus и Boeing, исследуют возможность внедрения таких технологий в будущие модели. Основное внимание уделяется созданию систем, которые смогут безопасно управлять полётами в условиях сложной погоды, включая грозы, и даже без участия пилота. Тем не менее, полная автономия ещё не реализована в гражданской авиации, и пилоты всё ещё остаются критически важными для обеспечения безопасности.


![ИИ](https://www.osp.ru/FileStorage/ARTICLE/Otkrytye_sistemy._SUBD/2024-03/01_24/13254950/Otkrytye_sistemy._SUBD_OS_01-2024-20_(1586).jpg "Создание ИИ")

Для знатоков:
![ИИ](https://ic.pics.livejournal.com/1500py470/62383590/1225213/1225213_original.jpg "Техналогии ИИ")


![ИИ](https://sergeeva-i.narod.ru/inform/page9.files/image002.jpg "Экспертные системы ИИ")




#### Немного о погоде:

***Искусственный интеллект в метеорологии: Технология прогнозов нового поколения***
1. Что это за инструмент?
Искусственный интеллект в метеорологии — это использование машинного обучения, нейросетей и других методов ИИ для анализа огромных объёмов данных о погоде, выявления закономерностей и составления более точных, быстрых и локализованных прогнозов.

Развитие:
* Изначально прогнозы погоды строились только на физических моделях атмосферы (например, уравнения Навье–Стокса).

* С развитием машинного обучения и облачных технологий, метеорологи стали использовать ИИ для ускорения вычислений и уточнения результатов.

* В 2023 году Google DeepMind представила GraphCast — модель, которая предсказывает глобальную погоду на 10 дней вперёд с большей точностью, чем традиционные численные методы.

2. Применение ИИ в метеорологии сегодня
ИИ используется для:

* Краткосрочного и долгосрочного прогнозирования: Модели могут предсказывать температуру, осадки, ветровые нагрузки и атмосферное давление с высокой точностью.

* Раннего предупреждения о стихийных бедствиях: ИИ может заранее определить вероятность ураганов, торнадо, наводнений или лесных пожаров.

* Микропрогнозов: Прогнозы на уровне отдельных городов или районов с учётом локальных факторов.

* Объединения различных источников данных: Спутниковые снимки, радары, метеостанции, данные IoT-устройств.

* Анализа климатических изменений: Выявление долгосрочных трендов потепления, таяния ледников и засух.

3. Преимущества
* Быстрее: Прогнозы, на которые раньше уходили часы на суперкомпьютере, можно получить за минуты.

* Точнее: ИИ умеет «видеть» нетривиальные закономерности, ускользающие от классических моделей.

* Локализованнее: Возможность точного прогноза погоды вплоть до конкретного адреса.

* Автоматизация: Метеостанции с ИИ могут сами анализировать и публиковать прогнозы без вмешательства человека.

4. Потенциальные проблемы
* «Чёрный ящик»: Решения ИИ не всегда интерпретируемы — сложно понять, почему он дал тот или иной прогноз.

* Зависимость от данных: Если входные данные будут неполными или ошибочными, прогноз тоже будет неточным.

* Высокие ресурсы: Некоторые модели требуют мощных вычислительных кластеров.

* Могут не учитывать физические ограничения: Например, неправильно предсказать силу шторма без моделирования законов физики.

5. Примеры использования
* Google DeepMind — GraphCast
Модель обучена на 40-летней истории погодных данных и теперь способна предсказывать глобальные погодные карты на 10 дней вперёд с большей точностью, чем Европейский центр среднесрочных прогнозов (ECMWF).

* IBM — Watson Weather
Использует ИИ для объединения данных с метеорологических спутников, радара и социальных сетей, чтобы предсказывать погоду и предупреждать о катастрофах.

* ClimaCell (теперь Tomorrow.io)
Применяет ИИ к данным с автомобилей, дронов и мобильных телефонов, чтобы составлять гиперлокальные прогнозы.


 Ссылка на источник: https://sfedu.ru/press-center/news/75740
![ИИ](https://sun9-58.userapi.com/impg/8G0LbfuLTJVQOflzF2vz_BqWQt1hyGrZKD9xcg/chndT9caz-Y.jpg?quality=95&sign=d5eed71f1b51c79802363efff53e607d&size=618x388&type=album "Прогнозировании погоды ИИ")




### DZ2

```txt
Домашнее задание

1. Выбор задачи. Выберите конкретную задачу или проблему, где внедрение ИИ может дать 
значительные преимущества. Это может быть любая отрасль или сфера, например, 
здравоохранение, финансы, маркетинг или транспорт. Четко определите задачу и ее цели.
2. Исследование. Проведите тщательное исследование технологических требований, 
необходимых для эффективного внедрения ИИ в выбранную задачу. Рассмотрите следующие 
аспекты:
a) Требования к аппаратному обеспечению. Определите аппаратные компоненты и 
инфраструктуру, необходимые для поддержки реализации ИИ. Сюда могут входить 
процессоры (CPU/GPUs/TPUs), память (RAM), хранилище, сетевые возможности и любое 
специализированное оборудование, специфичное для выбранной задачи.
b) Программное обеспечение. Изучите программное обеспечение и средства 
программирования, необходимые для реализации ИИ. Рассмотрите языки программирования 
и среды разработки, подходящие для выбранной задачи.
c) Сбор и управление данными. Проанализируйте требования к данным для решения задачи. 
Учитывайте емкость хранилища, качество данных и меры по обеспечению 
конфиденциальности данных.
3. Технологическая инфраструктура. На основе проведенного исследования опишите 
технологическую инфраструктуру, необходимую для реализации ИИ для выбранной задачи. 
Предоставьте подробное описание необходимого оборудования, программного обеспечения, 
управления данными.
4. Критический анализ. Критически оцените осуществимость и потенциальные проблемы 
внедрения ИИ для выбранной задачи на основе выявленных технологических требований. 
Обсудите любые ограничения и трудности, которые могут помешать успешной реализации.

```


 Ссылка на источник: https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/issues/1
![ИИ](https://private-user-images.githubusercontent.com/121765005/440823118-46eddf67-a0e4-432a-bf06-3f1af6ed355d.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDI1MDAsIm5iZiI6MTc0NjU0MjIwMCwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODIzMTE4LTQ2ZWRkZjY3LWEwZTQtNDMyYS1iZjA2LTNmMWFmNmVkMzU1ZC5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNDM2NDBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lMTJjYzMzMzFhMWMwNTE1MmUwZmIyZGU4MWU4NGVmOWQzNTgzNDg5ZTkyMGQ2OTBiOTk5ZWM3MDg2MmJjOTkxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.UckmnnTinqm4yK0lPhMTMXqP4j4V8MqodE4OLxk7qp8 "OpenCV imsges ИИ")

 Ссылка на источник: https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/tree/main/task02/screenshots
![ИИ](https://private-user-images.githubusercontent.com/121765005/440823121-e8f41de0-c0bb-4f9f-bb62-dd2016c4bd5a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDIxMjksIm5iZiI6MTc0NjU0MTgyOSwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODIzMTIxLWU4ZjQxZGUwLWMwYmItNGY5Zi1iYjYyLWRkMjAxNmM0YmQ1YS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNDMwMjlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYTE1MjNjMmVjZjk3ODczNmI2YjYzMWM5NDA3ZDVlMzMxZDA0YjkzYzJhNDhhYTBmNDczNzExOGQ5MDQ0ZmZkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.NikLFUyIqefZgNUB0NcWHRsyaoJ0Z-t-gOHOXKT0ICE "OpenCV video ИИ")

 Ссылка на источник: https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/tree/main/task02/screenshots
![ИИ](https://private-user-images.githubusercontent.com/121765005/440823120-cc1c8277-9303-4922-9951-c15b3eb17e6f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDIxMjksIm5iZiI6MTc0NjU0MTgyOSwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODIzMTIwLWNjMWM4Mjc3LTkzMDMtNDkyMi05OTUxLWMxNWIzZWIxN2U2Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNDMwMjlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kOWZlZmE0NTFlNzQ2ZDFlOTI3ZTVjZGQ5M2M5M2IxZTdkMTNjYmVkNDFhYTI1YmU3OGJmOTllMjE3ZDZhNDdjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.l0cC2AjXRU-p0FymqZQoRPByHSHEplOeZKdU6uVo4QE "OpenCV video ИИ")


Далее попробую использовать заранее обученную модель для распознования распознавания лица или тела человека.

Устанговим небходимые pip пакеты:
1) pip install opencv-python 
2) pip install mediapipe opencv-python
3) pip install ultralytics opencv-python

Для распознания лиц:
* import cv2
* запускаю image.py
* В результате получается нечто подобное:
 Ссылка на источник: https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/blob/main/task02/screenshots/04.jpg
![OpenCV images](https://private-user-images.githubusercontent.com/121765005/440823118-46eddf67-a0e4-432a-bf06-3f1af6ed355d.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDI1MDAsIm5iZiI6MTc0NjU0MjIwMCwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODIzMTE4LTQ2ZWRkZjY3LWEwZTQtNDMyYS1iZjA2LTNmMWFmNmVkMzU1ZC5qcGc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNDM2NDBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lMTJjYzMzMzFhMWMwNTE1MmUwZmIyZGU4MWU4NGVmOWQzNTgzNDg5ZTkyMGQ2OTBiOTk5ZWM3MDg2MmJjOTkxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.UckmnnTinqm4yK0lPhMTMXqP4j4V8MqodE4OLxk7qp8 "OpenCV imsges ИИ")

Для распознавания тела человека:

1) Первый варинт v1:
    * import cv2
    * Haar Cascade Classifiers из OpenCV, но они достаточно устарели и не очень надёжны для современных задач, особенно при плохом освещении или разных ракурсах. Лучше использовать более современные и обученные модели.
    * запускаю video.py
    *  В результате получается :
    Ссылка на источник: https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/blob/main/task02/screenshots/05.png
    ![OpenCV images](https://private-user-images.githubusercontent.com/121765005/440823121-e8f41de0-c0bb-4f9f-bb62-dd2016c4bd5a.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDIxMjksIm5iZiI6MTc0NjU0MTgyOSwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODIzMTIxLWU4ZjQxZGUwLWMwYmItNGY5Zi1iYjYyLWRkMjAxNmM0YmQ1YS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNDMwMjlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYTE1MjNjMmVjZjk3ODczNmI2YjYzMWM5NDA3ZDVlMzMxZDA0YjkzYzJhNDhhYTBmNDczNzExOGQ5MDQ0ZmZkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.NikLFUyIqefZgNUB0NcWHRsyaoJ0Z-t-gOHOXKT0ICE "OpenCV imsges ИИ")

2) Второй вариант MediaPipe (от Google) v2:
    * Очень лёгкий и быстрый, можно использовать с веб-камерой.
    * import mediapipe as mp
    * запускаю, тот же video.py, только v2
    * Компоненты:
        * pose – определяет тело и ключевые точки (33 точки).
        * holistic – полный трек: лицо, руки, тело. 
    * В результате получается :
    https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/blob/main/task02/screenshots/06.png
    ![OpenCV images](https://private-user-images.githubusercontent.com/121765005/440823120-cc1c8277-9303-4922-9951-c15b3eb17e6f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDIxMjksIm5iZiI6MTc0NjU0MTgyOSwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODIzMTIwLWNjMWM4Mjc3LTkzMDMtNDkyMi05OTUxLWMxNWIzZWIxN2U2Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNDMwMjlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kOWZlZmE0NTFlNzQ2ZDFlOTI3ZTVjZGQ5M2M5M2IxZTdkMTNjYmVkNDFhYTI1YmU3OGJmOTllMjE3ZDZhNDdjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.l0cC2AjXRU-p0FymqZQoRPByHSHEplOeZKdU6uVo4QE "OpenCV imsges ИИ")
3) Третий вариант   YOLO (You Only Look Once) v3(у меня показал лучший результат):
    * from ultralytics import YOLO
    * Запускаю, тот же video.py, только v3
    * Обнаруживает объекты, включая человека (label: person).
    * Высокая точность и скорость.
    * Подходит для обнаружения тел (bounding boxes), но не даёт ключевых точек.
    * Легко интегрируется через ultralytics/yolov5 или yolov8.
    * В результате получается :
    https://github.com/555-F-a-r-id-555/Fundamentals_of_Artificial_Intelligence/blob/main/task02/screenshots/08.png
    ![OpenCV images](https://private-user-images.githubusercontent.com/121765005/440823122-12fa3dc3-b567-4f5e-aa0a-78c4513be071.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDY1NDI4NTUsIm5iZiI6MTc0NjU0MjU1NSwicGF0aCI6Ii8xMjE3NjUwMDUvNDQwODIzMTIyLTEyZmEzZGMzLWI1NjctNGY1ZS1hYTBhLTc4YzQ1MTNiZTA3MS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUwNlQxNDQyMzVaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kNDQ1MmNlMjIzNjQ5NmM3ZGVkZGEwMzNiYWNiOWExNGZjYmZkMDZiOTkyNzY5NGNjZjY5NTM3NmQyMmZjZTQwJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.lMigh8fdKOo_IWJg3j5XEUhGQqrMRMpDTPKWyGRbd80 "OpenCV imsges ИИ")

4) Есть еще вариант от OpenPose (от Carnegie Mellon University) (этот виант я не протестировал):
    * Распознаёт все ключевые точки скелета человека
    * Поддерживает несколько людей в кадре.
    * Работает на C++, Python.
    * Есть Python-обёртки: openpose-python, tf-pose-estimation, mediapipe.
    *  Подходит для: skeleton detection, posture analysis, multi-person detection.
    * Сыылка на источник: https://github.com/CMU-Perceptual-Computing-Lab/openpose
    
    Требования для OpenPose:
    *  официальной инструкции: https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/installation/0_index.md
    * ОС: Ubuntu или Windows (WSL или CMake-сборка)
    * GPU (желательно)
    * CMake, CUDA, OpenCV, Python 3.8–3.10
    * Обязательная компиляция из исходников

5) Вывод:
    * YOLOv8: Bounding box человека — подойдёт для обнаружения и подсчёта людей.
    * MediaPipe: Ключевые точки тела — отлично для анализа поз, жестов, движения.


***Исследование технологических требований***

***a) Требования к аппаратному обеспечению***
Для эффективной работы OpenCV с ИИ (особенно при использовании таких моделей, как YOLO или OpenPose) требуются следующие компоненты:
* Минимальные требования:
* CPU: Intel i5 / AMD Ryzen 5 (или выше) — для базовой обработки изображений.
* RAM: от 8 ГБ — для работы с видео в реальном времени.
* Хранилище: SSD от 20–50 ГБ для хранения видео, моделей, логов.
* GPU (желательно):
    * Для задач распознавания в реальном времени желательно использовать GPU с поддержкой CUDA (например, NVIDIA GTX 1050 и выше).
    * OpenPose и YOLOv8 значительно выигрывают от ускорения на GPU.

* Опционально:
    * TPU / NPU (например, Google Coral, Jetson Nano) — для edge-решений и ускоренной обработки на устройствах IoT.
    * Камеры высокого разрешения — если задача требует точного позиционирования тела.

***b) Программное обеспечение***

| Компонент                        | Назначение                                         |
| -------------------------------- | -------------------------------------------------- |
| **Python (3.8–3.11)**            | Основной язык разработки                           |
| **OpenCV (cv2)**                 | Обработка изображений и видео                      |
| **Модели ИИ**                    | YOLO, MediaPipe, OpenPose                          |
| **CUDA Toolkit** (если есть GPU) | Для ускорения глубокого обучения на NVIDIA GPU     |
| **CMake + Visual Studio / gcc**  | Для сборки OpenPose из исходников                  |
| **OS**: Windows / Linux          | Оба подходят, но OpenPose легче собирать под Linux |

* Библиотеки и инструменты:
    * ultralytics, mediapipe, torch, numpy, opencv-python, matplotlib (по необходимости)
    * Для OpenPose — требуется собрать C++-библиотеку с Python API.

* IDE / Среды разработки:
    * VS Code, PyCharm, Jupyter Notebook — для разработки и отладки
    * Docker (опционально) — для портативности и изоляции окружения

***c) Сбор и управление данными***
* Требования к данным:
    *   Тип данных: изображения или видео (форматы: .mp4, .avi, .jpg, .png)
    *   Размер: может быть от нескольких МБ до десятков ГБ при длительной записи с камер

* Качество данных:
    *   Высокое разрешение улучшает точность распознавания
    *   Освещение, ракурсы и шумы могут повлиять на эффективность моделей

* Хранение и обработка:
    *   Локальное SSD хранилище или подключённые хранилища (NAS)
    *   Поддержка потоковой обработки (например, с IP-камер или RTSP)

* Конфиденциальность и защита:
*   При работе с персональными изображениями — нужно соблюдать:
    *   GDPR, локальные законы о защите персональных данных
    *   Применение анонимизации (размытие лиц, маскировка)
    *   Контроль доступа к хранилищам и логам

* Итог:

| Категория                   | Требования                                                             |
| --------------------------- | ---------------------------------------------------------------------- |
| **Аппаратное обеспечение**  | CPU i5+, GPU CUDA (если real-time), RAM ≥8 ГБ, SSD ≥50 ГБ              |
| **Программное обеспечение** | Python, OpenCV, Ultralytics/MediaPipe/OpenPose, CUDA, CMake            |
| **Данные**                  | Качественные изображения/видео, разумное хранилище, конфиденциальность |







### DZ3
```txt
Домашнее задание

1. Подумайте о реальной проблеме, которую, по вашему мнению, можно решить с помощью 
машинного обучения. Четко определите эту проблему и поставьте SMART-цели для ее 
решения. Помните, что это должна быть проблема, в которой машинное обучение может 
помочь сделать прогноз, классифицировать данные или дать рекомендации.
2. Определите потенциальные источники данных, которые могут быть использованы для 
решения вашей проблемы. Какие данные вам понадобятся? Где вы можете их получить? 
Напишите краткое резюме вашей стратегии сбора данных.
3. Даже если у вас нет реальных данных для анализа, представьте, что они у вас есть. Как бы 
вы стали исследовать и понимать эти данные? Что бы вы искали? Напишите краткое описание 
вашей стратегии анализа исследовательских данных.
4. Вспомните различные модели машинного обучения, которые мы обсуждали, в частности 
модель "Дерево решений". Какой тип модели машинного обучения будет наиболее 
подходящим для вашей проблемы и почему? Объясните свой выбор.
5. Напишите краткое описание того, как вы будете обучать и оценивать выбранную вами 
модель машинного обучения, используя воображаемый набор данных.
6. Наконец, подумайте о том, как вы могли бы развернуть свою обученную модель. Где она 
будет использоваться? Кто будет ее использовать? Какую пользу она принесет им? Напишите 
краткое резюме вашей стратегии развертывания.
Помните, что целью этого задания является не создание реальной модели машинного 
обучения (пока!), а применение концепций, которые вы изучили на этом семинаре, к реальной 
проблеме.

```
Хотел начать с этих слов:
```txt
 We are living in an era of constant technological progress, 
 and looking at how computing has advanced over the years,
 we can predict what’s to come in the days ahead.
Мы живем в эпоху постоянного технологического прогресса, и, 
глядя на то, как развивалась вычислительная техника за эти годы, мы можем предсказать, 
что нас ждет в будущем.

```
```txt
В мире, где почти все ручные задачи автоматизированы, определение ручного труда меняется. Сейчас существует множество различных типов алгоритмов машинного обучения, некоторые из которых могут помочь компьютерам играть в шахматы, проводить операции и становиться умнее и персональнее. Мы живем в эпоху постоянного технологического прогресса, и глядя на то, как развивались вычисления на протяжении многих лет, мы можем предсказать, что произойдет в будущем. 

В быстро развивающейся области машинного обучения понимание правильных алгоритмов имеет решающее значение для любого начинающего инженера или специалиста по данным.
```
***Алгоритм — это процедура обучения, то есть способ, по которому модель обучается.***
***Модель — это результат применения алгоритма к данным, то есть то, что потом используется для предсказаний.***

***10 лучших алгоритмов машинного обучения:***
1)  Линейная регрессия
2)  Логистическая регрессия
3)  Дерево решений
4)  Алгоритм SVM
5)  Наивный байесовский алгоритм
6)  алгоритм КНН
7)  К-средние
8)  Алгоритм случайного леса
9)  Алгоритмы снижения размерности
10) Алгоритм градиентного усиления и алгоритм AdaBoosting

https://cloud.vk.com/blog/samye-populyarnye-algoritmy-mashinnogo-obucheniya/

***Типы алгоритмов машинного обучения***
1) Supervised Learning ( Контролируемое обучение - обучение с учителем)
2) Unsupervised Learning ( Обучение без учителя)
3) Reinforcement Learning ( Обучение с подкреплением)

1. **Алгоритмы контролируемого обучения** обучаются с использованием маркированных данных, что означает, что входные данные помечены правильным выходом. Цель этих алгоритмов — изучить сопоставление входных данных с выходными данными, что позволяет предсказывать выходные данные для новых данных. Обычные алгоритмы контролируемого обучения включают:
    * **Линейная регрессия**: используется для прогнозирования непрерывных результатов. Она моделирует связь между зависимой переменной и одной или несколькими независимыми переменными путем подгонки линейного уравнения к наблюдаемым данным.
        * Эта линия известна как линия регрессии и представлена ​​линейным уравнением Y= k * X + b.
            * В этом уравнении:
               *  Y – зависимая переменная
               *  K – Наклон
               *  X – Независимая переменная
               *  b – Перехват.
               Коэффициенты a и b выводятся путем минимизации суммы квадратов разности расстояний между точками данных и линией регрессии.
    * **Логистическая регрессия**: Логистическая регрессия используется для оценки дискретных значений (обычно бинарных значений, таких как 0/1) из набора независимых переменных. Она помогает предсказать вероятность события, подгоняя данные под логит-функцию. Она также называется логит-регрессией.
        * Модель логистической регрессии описывается уравнением:
        * P(y = 1 | x) = 1 / (1 + exp(-(wᵗx + b)))
            Где:
            - `x` — вектор признаков (входные данные),
            - `w` — вектор весов,
            - `b` — смещение (bias),
            - `exp` — экспоненциальная функция (e в степени),
            - `P(y = 1 | x)` — вероятность того, что результат равен 1.

    * **Дерево решений** — это алгоритм контролируемого обучения, который используется для решения задач классификации и регрессии. Он особенно популярен благодаря своей интерпретируемости. Алгоритм последовательно делит исходные данные на подмножества, основываясь на значениях наиболее информативных признаков, создавая древовидную структуру с вершинами и листами.
    Дерево хорошо справляется с категориальными и непрерывными переменными.
    На каждом шаге дерево выбирает признак, по которому деление увеличит "чистоту" подмножеств — на основе метрик разделения, таких как информационный прирост, энтропия или индекс Джини.
        * Математические основы:
        * Энтропия:
        * H(S) = - Σ pᵢ * log₂(pᵢ)
        * Где:
        - `H(S)` — энтропия множества `S`,
        - `pᵢ` — доля элементов класса `i` в выборке.
        * Информационный прирост:
        * IG(S, A) = H(S) - Σ (|Sᵥ| / |S|) * H(Sᵥ)
        * Где:
        - `IG(S, A)` — прирост информации при разбиении множества `S` по признаку `A`,
        - `Sᵥ` — подмножество, в котором признак `A` имеет значение `v`.
        * Индекс Джини:
        * Gini(S) = 1 - Σ pᵢ²
        * Где:
        - `Gini(S)` — индекс Джини для множества `S`,
        - `pᵢ` — вероятность принадлежности случайного элемента к классу `i`.
    * **Алгоритм случайного леса**: совокупность деревьев решений, обычно используемых для классификации и регрессии, повышающих точность модели и контроль переобучения.
    * **Метод опорных векторов (SVM)**: эффективный в многомерных пространствах, SVM в основном используется для классификации, но может также использоваться для регрессии.
        * Алгоритм SVM — это метод алгоритма классификации, в котором вы отображаете необработанные данные в виде точек в n-мерном пространстве (где n — количество имеющихся у вас признаков). Значение каждого признака затем привязывается к определенной координате, что упрощает классификацию данных. Линии, называемые классификаторами, можно использовать для разделения данных и их отображения на графике
    * **Нейронные сети**: Это мощные модели, которые могут улавливать сложные нелинейные отношения. Они широко используются в приложениях глубокого обучения.
    2. **Обучение без учителя**. Алгоритмы неконтролируемого обучения используются с наборами данных без маркированных ответов. Цель здесь — вывести естественную структуру, присутствующую в наборе точек данных. Распространенные методы неконтролируемого обучения включают:
    * **Кластеризация**: такие алгоритмы, как K-средние, иерархическая кластеризация и DBSCAN, группируют набор объектов таким образом, что объекты в одной группе более похожи друг на друга, чем на объекты в других группах. Наборы данных классифицируются в определенное количество кластеров (назовем это число K) таким образом, что все точки данных в кластере однородны и неоднородны по отношению к данным в других кластерах.
    * **Ассоциация**: эти алгоритмы находят правила, описывающие большие части ваших данных, такие как анализ потребительской корзины.
    * **Анализ главных компонент (PCA)**: статистическая процедура, которая использует ортогональное преобразование для преобразования набора наблюдений возможно коррелированных переменных в набор значений линейно некоррелированных переменных.
    * Автокодировщики: особый тип нейронной сети, используемый для обучения эффективному кодированию немаркированных данных.

    3. **Обучение с подкреплением**. Алгоритмы обучения с подкреплением учатся принимать последовательность решений. Алгоритм учится достигать цели в неопределенной, потенциально сложной среде. При обучении с подкреплением агент принимает решения, следуя политике, основанной на том, какие действия следует предпринять, и учится на последствиях этих действий с помощью вознаграждений или штрафов.
    * **Q-learning** — это алгоритм обучения с подкреплением без модели (model-free), который позволяет агенту **обучаться оптимальной стратегии**, изучая значения действий в каждом состоянии.  Он стремится найти **оптимальную функцию Q**, которая будет указывать, насколько полезно выполнять то или иное действие в заданном состоянии.
        * Цель: Максимизировать кумулятивное вознаграждение, изучая функцию Q:

            \[
            Q(s, a) = \text{ожидаемое суммарное вознаграждение при выборе действия } a \text{ в состоянии } s
            \]

        * Особенности: 
        - **Off-policy**: обучение происходит независимо от политики, используемой для выбора действий (обычно используется ε-greedy).
        - Может использоваться в дискретных пространствах состояний и действий.
        - Подходит для задач с конечным числом состояний и действий.
        * Пример применения:
        - Игра в лабиринт
        - Простые игры (FrozenLake, Taxi-v3 в OpenAI Gym)
        - Управление роботами в дискретных средах
        * Q-learning является основой для более сложных методов, таких как Deep Q-Network (DQN), где функция Q аппроксимируется нейросетью.

        * https://habr.com/ru/companies/otus/articles/803041/
    * **Глубокие Q-сети (DQN)**: — это метод, который сочетает в себе **Q-learning** и **глубокие нейронные сети** для аппроксимации функции Q. DQN позволяет обучать агентов успешным стратегиям непосредственно на основе **многомерных сенсорных данных** (например, изображений), что делает его мощным инструментом для сложных задач в реальном мире.Как и в традиционном Q-learning, цель DQN — найти **оптимальную функцию Q**, которая определяет, насколько хороши те или иные действия в различных состояниях. Однако в DQN эта функция аппроксимируется с использованием нейронной сети, которая обучается на данных.
        * Ключевые особенности:
        1. **Целевая сеть (Target Network)**: используется для стабилизации обучения. Это копия сети, которая обновляется редко, чтобы уменьшить колебания.
        2. **Опытный буфер (Experience Replay)**: для улучшения устойчивости и снижения корреляции между последовательными обучающимися примерами, опыт (состояние, действие, вознаграждение, следующее состояние) сохраняется в буфере и случайным образом используется для обновлений.
        3. **Нейронная сеть**: используется для аппроксимации функции Q, которая позволяет эффективно работать с большими и сложными пространствами состояний (например, изображения).
        * Применение:
        - Игры с изображениями (например, **Atari**)
        - Робототехника, где сенсоры генерируют большие объемы данных
        - Навигация и управление сложными системами в реальном времени
        * DQN стал основным методом, использующимся в глубоком обучении для задач обучения с подкреплением и проложил путь к более сложным методам, таким как Double DQN, Dueling DQN, и A3C(Asynchronous Advantage Actor-Critic).

        * https://habr.com/ru/companies/wunderfund/articles/671650/
    * **Методы градиента политики**: Методы градиента политики являются классом алгоритмов обучения с подкреплением, которые **напрямую оптимизируют стратегию (policy)** — функцию, определяющую вероятности выбора действий в каждом состоянии.
        В отличие от методов ценности (например, Q-Learning), эти методы **не оценивают функцию ценности**, а вместо этого обучают параметризованную стратегию π(a|s, θ), где:
        - `s` — состояние,
        - `a` — действие,
        - `θ` — параметры модели (например, веса нейросети).
        * Цель Максимизировать **ожидаемое вознаграждение**:

            \[
            J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} [R(\tau)]
            \]

            где:
            - `τ` — траектория (последовательность состояний и действий),
            - `R(τ)` — суммарное вознаграждение за траекторию.

        * Обновление параметров
            * Обновление параметров стратегии выполняется с использованием **градиента ожидаемой награды** (Policy Gradient Theorem):
            
            \[
            \nabla_\theta J(\theta) = \mathbb{E}_{\pi_\theta} \left[ \nabla_\theta \log \pi_\theta(a|s) \cdot Q^{\pi}(s, a) \right]
            \]

            * На практике применяется метод REINFORCE:

            \[
            \theta \leftarrow \theta + \alpha \cdot \nabla_\theta \log \pi_\theta(a|s) \cdot R
            \]

            где:
            - `α` — скорость обучения,
            - `R` — полученное вознаграждение.
            
            * Применение
                - Управление роботами
                - ИИ в играх (например, Atari, AlphaStar)
                - Обучение агентов с непрерывным пространством действий

            * Основное преимущество: методы градиента политики хорошо работают с непрерывными и стохастическими стратегиями.

        * https://habr.com/ru/articles/555202/
    * **MCTS (Monte Carlo Tree Search)** — это алгоритм поиска, применяемый в задачах принятия решений, таких как игры с полной информацией (например, го, шахматы, крестики-нолики), а также в планировании и задачах управления агентом.
        * Алгоритм использует **случайные симуляции (монте-карло)** для оценки качества действий и **построения дерева поиска**, балансируя **исследование (exploration)** и **эксплуатацию (exploitation)**.
        * Этапы MCTS:
        1. **Selection (Выбор)**: проход по дереву от корня до листа по правилу наилучшего баланса между исследованием и эксплуатацией.
        2. **Expansion (Расширение)**: добавление новых узлов к дереву.
        3. **Simulation (Симуляция)**: случайное (или эвристическое) проигрывание сценария до конца.
        4. **Backpropagation (Обратное распространение)**: обновление статистики на пути обратно к корню дерева.
        * Формула выбора узла (UCT — Upper Confidence bound applied to Trees):
        * Для выбора узла применяется формула UCT:
        * UCT = (wᵢ / nᵢ) + C * √(ln N / nᵢ)
        * Где:
        - `wᵢ` — суммарная награда в узле `i`
        - `nᵢ` — количество посещений узла `i`
        - `N` — количество посещений родительского узла
        - `C` — коэффициент для настройки баланса (обычно `≈ √2`)
        * Применение
        - ИИ в играх (AlphaGo)
        - Планирование действий в робототехнике
        - Умные агенты в обучении с подкреплением
        * Преимущество MCTS — нет необходимости заранее обучать модель; достаточно симулировать поведение и принимать решения на основе статистики.

        [MCTS](https://vgarciasc.github.io/mcts-viz "интерактивная визуализация алгоритма MCTS на примере игры «Крестики-нолики»") интерактивная визуализация алгоритма MCTS на примере игры «Крестики-нолики»
        

    * https://habr.com/ru/companies/selectel/articles/794658/
    * https://habr.com/ru/articles/282522/


    Не забывем про такие агортмы как:
    * **Наивный байесовский классификатор (Naive Bayes classifier)** — вероятностный классификатор на основе формулы Байеса со строгим (наивным) предположением о независимости признаков между собой при заданном классе, что сильно упрощает задачу классификации из-за оценки одномерных вероятностных плотностей вместо одной многомерной.
        * Математическая формула:
        * Классификация осуществляется по формуле Байеса:
        * P(C | X) = (P(X | C) * P(C)) / P(X)
        * Где:
        - `C` — класс,
        - `X = (x₁, x₂, ..., xₙ)` — вектор признаков,
        - `P(C | X)` — апостериорная вероятность класса при известных признаках,
        - `P(X | C)` — вероятность признаков при данном классе (по наивному допущению: `P(X | C) = Π P(xᵢ | C)`),
        - `P(C)` — априорная вероятность класса,
        - `P(X)` — полная вероятность признаков (общий знаменатель; одинаков для всех классов и можно игнорировать при выборе класса).
        Классификация происходит по правилу максимума апостериорной вероятности (MAP)
        *Наивный Байес, или о том, как математика позволяет фильтровать спам:*
        * https://habr.com/ru/articles/415963/
        * https://habr.com/ru/articles/802435/
    * **Алгоритм KNN (K-ближайших соседей)**.Этот алгоритм можно применять как к задачам классификации, так и к задачам регрессии. По-видимому, в отрасли Data Science он более широко используется для решения задач классификации. Это простой алгоритм, который хранит все доступные случаи и классифицирует любые новые случаи, принимая большинство голосов своих k соседей. Затем случай назначается классу, с которым у него больше всего общего. Функция расстояния выполняет это измерение.
        KNN можно легко понять, сравнив его с реальной жизнью. Например, если вам нужна информация о человеке, имеет смысл поговорить с его друзьями и коллегами!
        Алгоритм работает по следующему принципу:
        1. Сохраняет все обучающие примеры;
        2. При классификации нового примера — находит **`k` ближайших** к нему объектов;
        3. Класс выбирается по **большинству голосов** соседей (в классификации) или по **среднему значению** (в регрессии).

        Это **ленивый (instance-based)** метод — обучение как таковое отсутствует, всё происходит на этапе предсказания.
        * Математическая основа
        * Расстояние между точками (например, Евклидово):
        * d(x, xᵢ) = sqrt(Σ (xⱼ - xᵢⱼ)²)
        * Где:
        - `x` — входной вектор для предсказания,
        - `xᵢ` — обучающий пример,
        - `xⱼ`, `xᵢⱼ` — соответствующие признаки,
        - `d(x, xᵢ)` — расстояние между точками.
        - Можно использовать и другие метрики расстояния, например:
        - Манхэттенское расстояние
        - Косинусная мера
        - Чебышевское расстояние
        * Важные замечания:
        -  Алгоритм чувствителен к **масштабу признаков** — рекомендуется **нормализация данных**;
        - При большом объёме данных требует **высоких вычислительных ресурсов**;
        - KNN — **не устойчив к выбросам** и **шуму**, требует предварительной обработки;
        - Выбор значения **k** критически важен:
        - Маленькое `k` может привести к переобучению (overfitting),
        - Слишком большое `k` — к недообучению (underfitting).
        - Аналогия: если вы хотите узнать мнение о человеке, спросите его ближайших друзей — KNN работает по такому же принципу!
        * https://habr.com/ru/articles/801885/
    * **Алгоритмы снижения размерности**.
        В условиях, когда организации обрабатывают огромные объёмы данных с сотнями и тысячами признаков, возникает необходимость **снизить размерность**, сохранив как можно больше полезной информации.
        * Алгоритмы снижения размерности позволяют:
        - уменьшить избыточность признаков,
        - ускорить обучение моделей,
        - бороться с переобучением,
        - визуализировать данные в 2D или 3D пространств
        ------------------------------------------------------------------------------
        * Популярные методы:
            1. PCA (Principal Component Analysis, Метод главных компонент)
            * Находит новые оси (компоненты), которые максимально объясняют дисперсию данных.
            * Формула: Z = X · W
            * Где:
            - `X` — матрица исходных данных,
            - `W` — матрица собственных векторов (направлений максимальной дисперсии),
            - `Z` — проекция данных в новом пространстве. 
            2. t-SNE (t-Distributed Stochastic Neighbor Embedding)
            * Метод нелинейного снижения размерности, особенно полезный для **визуализации данных**. Сохраняет локальную структуру данных.
            * 3. UMAP (Uniform Manifold Approximation and Projection)
            * Быстрый и эффективный метод нелинейного снижения размерности, часто превосходит t-SNE по скорости и сохранению глобальной структуры.
            * 4. Факторный анализ
            * Похож на PCA, но предполагает наличие **скрытых латентных факторов**, влияющих на наблюдаемые переменные. Используется в статистике и психометрии.
            
        * https://habr.com/ru/articles/751050/

        * https://habr.com/ru/companies/newprolab/articles/350584/
    * **Алгоритмы Boosting: Gradient Boosting и AdaBoost**. Boosting (повышение) — это метод ансамблевого обучения, в котором несколько **слабых моделей** (например, деревья решений с малой глубиной) последовательно обучаются, а их ошибки исправляются следующими моделями. В результате формируется **сильный предсказатель**.
    Boosting позволяет добиться высокой точности и часто используется в соревнованиях по Data Science (Kaggle, DrivenData, CrowdAnalytix и др.).
        * **AdaBoost (Adaptive Boosting)**:
        Алгоритм обучает слабые модели последовательно, каждый раз усиливая внимание на ошибочно классифицированных объектах.
        * Математическая суть:
        * На каждой итерации `t`:
        - Каждому примеру присваивается вес `wᵢᵗ`, увеличивающийся, если он классифицирован неверно.
        - Обучается слабый классификатор `hₜ(x)`.
        - Вычисляется коэффициент αₜ:
        * αₜ = 0.5 * ln((1 - εₜ) / εₜ)
        где `εₜ` — ошибка классификатора на взвешенной выборке.
        * - Финальное предсказание:
        * H(x) = sign(Σ αₜ * hₜ(x))
        * **Gradient Boosting**Gradient Boosting — это обобщение бустинга, в котором каждая новая модель обучается **на градиенте функции потерь** по ошибкам предыдущих моделей.
        * На шаге `t` добавляется новая модель `hₜ(x)`, которая минимизирует ошибку:
        * Fₜ(x) = Fₜ₋₁(x) + η * hₜ(x)
        - `Fₜ(x)` — ансамбль на текущем шаге
        - `η` — скорость обучения (learning rate)
        - `hₜ(x)` — модель, приближающая антиградиент функции потерь
        * Gradient Boosting может использовать любую дифференцируемую функцию потерь (например, MSE, логистическую функцию и т.д.).
        * Почему использовать Boosting?
            - Высокая точность
            - Устойчивость к переобучению при правильной настройке
            - Возможность использовать разные функции потерь
        * Популярные реализации
            - `XGBoost` — быстрый, регуляризуемый бустинг
            - `LightGBM` — оптимизированный для больших данных
            - `CatBoost` — хорошо работает с категориальными признаками
        * **Boosting — один из самых мощных методов машинного обучения, особенно при работе с табличными данными.**



 -------------------------------------------------------------------------------------------------
* Gradient Descent(Градиентный спуск) — это метод оптимизации.
Пример применения: обучение весов в логистической регрессии.
* https://habr.com/ru/articles/716380/
* Gradient Boosting( Усиление градиента ) — это метод построения ансамбля моделей, использующий градиенты для вычисления ошибки, а не для оптимизации параметров напрямую.
Пример применения: XGBoost, LightGBM, CatBoost.
* https://habr.com/ru/companies/otus/articles/503888/

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
DZ
1. Часть первая:
    * Проблема: Прогнозирование оттока клиентов в интернет-банкинге
    * Формулировка проблемы:
        Интернет-банк теряет часть клиентов, которые перестают пользоваться его услугами (отток). 
        Проблема заключается в том, что банк не знает заранее, какие клиенты собираются уйти, а значит, 
        не может вовремя предложить персональные предложения, скидки или сервис для удержания.
    * Почему это задача для машинного обучения:
        Это задача классификации: на основе исторических данных о поведении клиентов можно обучить модель, 
        которая будет предсказывать вероятность оттока (churn prediction).
    * SMART-цели:
        | Компонент          | Цель                                                                                                                       |
        | ------------------ | -------------------------------------------------------------------------------------------------------------------------- |
        | **S (Specific)**   | Построить модель, предсказывающую, уйдёт ли клиент в ближайший месяц.                                                      |
        | **M (Measurable)** | Достичь не менее **85% точности (accuracy)** или **ROC AUC ≥ 0.9** на тестовых данных.                                     |
        | **A (Achievable)** | Использовать имеющиеся клиентские данные (транзакции, обращения в поддержку, логины, платежи) — доступ к данным обеспечен. |
        | **R (Relevant)**   | Снижение оттока на **10%** позволит сэкономить значительные средства на привлечение новых клиентов.                        |
        | **T (Time-bound)** | Завершить разработку и внедрение модели за **3 месяца**, включая анализ, обучение, тестирование и интеграцию в CRM.        |
2. Часть вторая:
    * Потенциальные источники данных и стратегия сбора
    * Какие данные нужны:
        * 1.Профиль клиента:
            * Возраст, пол, регион, дата регистрации, канал привлечения.
        * 2.Поведение в системе:
            * Частота логинов.
            * Последний вход в систему.
            * Используемые функции (переводы, вклады, оплата услуг).
        * 3.Финансовая активность:
            * Баланс на счету, частота транзакций, суммы переводов.
            * Наличие кредитов/вкладов.
        * 4.Обращения в поддержку:
            * Кол-во тикетов, типы обращений, тональность (если есть).
        * 5.История оттока (метка класса):
            * Метка: ушёл клиент или нет за последние X дней.

        * Где взять данные:
            * Внутренние базы данных банка (PostgreSQL, Oracle и др.).
            * Лог-файлы серверов (активность в приложении, веб-интерфейсе).
            * CRM-системы (Salesforce, Bitrix и т.д.).
            * Системы поддержки (Zendesk, JIRA ServiceDesk).
    * Важно: соблюдение GDPR/законодательства о защите персональных данных — использовать обезличивание или агрегированные данные.

        * Стратегия сбора данных:
            * Сформулировать SQL-запросы для извлечения нужных признаков.
            * Объединить данные по client_id.
            * Очистить и сохранить в формате .csv или загружать в DataFrame напрямую.
            * Настроить регулярную выгрузку (еженедельную/ежемесячную) для обновления модели.
    
 3. Часть третья. Исследование и анализ данных (EDA):
    * Понять структуру данных, выявить закономерности, определить важные признаки для обучения модели и подготовить данные для моделирования.
    * Что исследовать:
        * 1. Общие характеристики данных:
            * Кол-во строк и столбцов, пропуски (df.info()).
            * Распределение классов: сколько клиентов ушло, сколько нет.
            * Статистики (describe()): среднее, медиана, отклонение.
        * 2. Анализ признаков: 
            * Распределение активности пользователей по дням/часам.
            * Влияние возраста, региона, активности на отток.
            * Частота и сумма транзакций у тех, кто ушёл.
            * Кол-во обращений в поддержку у ушедших vs оставшихся.
        * 3. Корреляции и визуализация:
            * heatmap для корреляционной матрицы.
            * Гистограммы, boxplot'ы для сравнения между классами.
            * Временные ряды: динамика активности перед уходом.
        * 4. Обнаружение выбросов и аномалий:
            * Клиенты с экстремально высокой или нулевой активностью.
            * Проверка на дубликаты, ошибочные значения.

    * Инструменты анализа:

            | Этап                 | Инструменты                 |
            | -------------------- | --------------------------- |
            | Чтение и очистка     | Pandas, NumPy               |
            | Визуализация         | Seaborn, Matplotlib, Plotly |
            | Обнаружение аномалий | Isolation Forest, Z-score   |
            | Интерпретация        | SHAP (на следующем этапе)   |
4. Часть четвертая. Выбор подходящего типа модели машинного обучения
    * Задача:
        * Бинарная классификация: предсказать, уйдёт клиент (1) или останется (0).
    * Подходящие модели: 

    | Модель                                              | Преимущества                                                                                 |
    | --------------------------------------------------- | -------------------------------------------------------------------------------------------- |
    | **Logistic Regression(Логистическая регрессия)**                             | Простая, интерпретируемая, даёт базовую точку отсчёта                                        |
    | **Random Forest(Алгоритм случайного леса)**                                   | Хорошо работает с категориальными и числовыми данными, устойчив к выбросам                   |
    | **Gradient Boosting (например, XGBoost, LightGBM)(Усиление градиента)** | Высокая точность, хорошо работает с табличными данными, умеет определять важные признаки     |
    | **CatBoost**                                        | Отлично справляется с категориальными признаками без кодирования, высокая производительность |

    * CatBoost – алгоритм, разработанный Yandex это это гармоничное сочетание инноваций и эффективности, особенно когда дело доходит до работы с категориальными данными.
    https://habr.com/ru/companies/otus/articles/778714/

    * Выбор:
        * Gradient Boosting (например, XGBoost или CatBoost)
            * Работает лучше всего на табличных данных, как в задаче оттока.
            * Устойчив к несбалансированным классам.
            * Поддерживает оценку важности признаков.
            * Гибкий: можно адаптировать под бизнес-требования (например, максимизировать Recall).
    
5. Часть пятая. Обучение и оценка модели на воображаемом наборе данных:

    * Этапы:

        1. Разделение данных:

            ```python
            from sklearn.model_selection import train_test_split

            X = data.drop(columns=['churn'])  # признаки
            y = data['churn']                 # целевая переменная (0/1)

            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

            ```

            2. Обучение модели (XGBoost):

            ```python
            from xgboost import XGBClassifier

            model = XGBClassifier(scale_pos_weight=5, eval_metric='logloss')  # учитываем дисбаланс
            model.fit(X_train, y_train)

            ```

            3. Оценка модели:

            ```python
            from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

            y_pred = model.predict(X_test)
            y_prob = model.predict_proba(X_test)[:, 1]

            print(classification_report(y_test, y_pred))
            print("ROC AUC:", roc_auc_score(y_test, y_prob))

            ```

            * Метрики:
                * Recall (полнота) — важно не упустить "уходящих" клиентов.
                * Precision — важно не перегружать маркетинг ложными тревогами.
                * ROC AUC — устойчивая метрика для дисбалансированных классов.
                * Confusion Matrix — показывает, кого модель чаще ошибочно относит к "ушедшим" или "остававшимся".

            4.Кросс-валидация и настройка параметров:

            ```python
            from sklearn.model_selection import cross_val_score

            scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')
            print("Средний AUC по кросс-валидации:", scores.mean())

            ```

        * https://www.kaggle.com/datasets/blastchar/telco-customer-churn/data

    * Общие результаты:
        *  Размер датасета: (7043, 21) — всё загружено корректно.
        *  Accuracy: 0.75 — модель правильно классифицирует 75% примеров.
        *  ROC AUC: 0.82 — это метрика, показывающая способность отличать "ушедших" клиентов от "оставшихся". Значение выше 0.8 — хорошо!
        *  Кросс-валидация: Средний ROC AUC ≈ 0.818 — модель стабильна, нет переобучения.

    * Анализ качества по классам:

    | Метрика   | Не ушёл (0) | Ушёл (1) |
    | --------- | ----------- | -------- |
    | Precision | 0.87        | 0.52     |
    | Recall    | 0.77        | 0.69     |
    | F1-score  | 0.82        | 0.59     |

    * Recall для "ушедших" (0.69) — это значит, что модель находит 69% реально ушедших клиентов. Это важный показатель для задачи оттока.
    * Precision для "ушедших" (0.52) — из всех предсказанных как "ушедшие", только 52% действительно ушли. Это нормально, если целью является предотвращение потерь.

6. Часть шестая. Стратегия развертывания модели.
    * Где будет использоваться модель:
        * Модель будет развернута как REST API-сервис на сервере компании (например, с использованием Flask/FastAPI + Docker) и интегрирована в   CRM-систему телекоммуникационного провайдера.
    * Кто будет её использовать:
        * Менеджеры по удержанию клиентов: будут получать список клиентов с высокой вероятностью оттока и предпринимать меры (скидки, персональные предложения).
        * Отдел маркетинга: для построения целевых кампаний на основе предсказанных результатов.
        * Системные администраторы: будут обслуживать и контролировать корректную работу модели.
    * Какую пользу она принесет:
        * Уменьшение оттока клиентов за счёт своевременного выявления рисков.
        * Повышение прибыли за счёт удержания постоянных клиентов (меньше затрат на привлечение новых).
        *  Более эффективные маркетинговые стратегии, основанные на данных.
    * Дополнительно:
        * Модель будет периодически переобучаться на новых данных (например, раз в месяц).
        * Все предсказания будут логироваться и использоваться для мониторинга качества модели в реальном времени (через метрики: Precision, Recall, AUC).
        * Возможна интеграция в дашборд для визуализации результатов и анализа причин оттока.




### DZ4
```txt
Домашнее задание
Сценарий:
Вы были наняты в качестве консультанта производственной компанией, которая хочет изучить 
потенциальные преимущества внедрения ИИ в свой производственный процесс. Компания 
производит бытовую электронику и стремится повысить эффективность, сократить количество 
отходов и улучшить качество продукции.
Ваша задача - подготовить отчет, в котором будет изложен план внедрения ИИ для 
производственной компании. 
В отчете должны быть рассмотрены следующие аспекты:
1. Дайте обзор компании и ее производственного процесса.
Четко сформулируйте задачи и цели внедрения ИИ в производственный процесс.
2. Проанализируйте текущий производственный процесс и определите потенциальные области, 
в которых ИИ может принести улучшения.
Рассмотрите такие аспекты, как контроль качества, предиктивное обслуживание, оптимизация 
цепочки поставок или эффективность производственной линии.
3. Предложите конкретные методы, алгоритмы или технологии ИИ, которые могут быть 
использованы для решения выявленных возможностей. Объясните, как каждое предлагаемое 
решение ИИ может улучшить производственный процесс и достичь желаемых целей.
4. Опишите типы данных, которые необходимо собрать и использовать для внедрения ИИ. 
Обсудите методы сбора, хранения и интеграции данных в производственный процесс.
5. Разработайте пошаговый план внедрения ИИ в производственный процесс. Включите сроки, 
требования к ресурсам и потенциальные проблемы, которые могут возникнуть в процессе 
внедрения. Рассмотрите такие аспекты, как приобретение технологий, обучение сотрудников и 
управление изменениями.
6. Оцените ожидаемые выгоды от внедрения ИИ, такие как повышение эффективности 
производства, сокращение отходов, повышение качества продукции или экономия затрат.
7. Обсудите потенциальные этические соображения, которые могут возникнуть при внедрении 
ИИ в производственный процесс. Предложите стратегии и меры по обеспечению 
ответственного и этичного внедрения ИИ, учитывая такие аспекты, как конфиденциальность, 
предвзятость и прозрачность
```
#### Отчёт: План внедрения ИИ в производственный процесс компании по выпуску бытовой электрони

**1. Обзор компании и целей внедрения ИИ**

- Компания
Компания специализируется на производстве бытовой электроники, включая мелкую кухонную технику (блендеры, тостеры, кофеварки) и товары для дома (очистители воздуха, увлажнители и пр.). Производственный процесс включает этапы сборки, тестирования, упаковки и логистики. Производство частично автоматизировано, но во многих зонах ещё используется ручной труд и ручной контроль качества.
* Цели внедрения ИИ:
- Повысить эффективность производственной линии.
- Снизить количество производственного брака и отходов.
- Внедрить предиктивное обслуживание для минимизации простоев.
- Оптимизировать управление поставками и складскими запасами.
- Повысить конкурентоспособность и технологическую зрелость компании.

**2. Анализ текущего производственного процесса и потенциальные области применения ИИ**

*Контроль качества:*

- Сейчас контроль осуществляется вручную на выборочных образцах.
- Часто выявление дефектов происходит слишком поздно, что ведёт к переработке и браку.

*Предиктивное обслуживание:*
- Оборудование обслуживается по регламенту или в случае поломки.
- Часты незапланированные простои.

*Оптимизация цепочки поставок:*
- Планирование поставок и логистики ведётся с запозданием.
- Бывают перебои в поставках и избыток на складе.

*Эффективность производственной линии:*
- Недостаточно данных для анализа узких мест.
- Неоптимальное распределение задач между линиями.

**3. Предлагаемые ИИ-решения и технологии**

| Область                       | Решение                                            | ИИ-технологии                                               | Ожидаемый эффект                                         |
| ----------------------------- | -------------------------------------------------- | ----------------------------------------------------------- | -------------------------------------------------------- |
| Контроль качества             | Автоматический визуальный контроль с помощью камер | Компьютерное зрение, CNN (нейросети)                        | Снижение брака, постоянный контроль без участия человека |
| Предиктивное обслуживание     | Анализ сигналов от датчиков на оборудовании        | Машинное обучение, аномалия-детекция, временные ряды (LSTM) | Предотвращение поломок, сокращение простоев              |
| Оптимизация логистики         | Прогнозирование спроса, оптимизация запасов        | ML-модели, XGBoost, оптимизационные алгоритмы               | Снижение затрат, избежание излишков                      |
| Производственное планирование | Интеллектуальное распределение задач и заказов     | Reinforcement Learning, эвристики                           | Рост пропускной способности, снижение задержек           |

**4. Типы данных и методы работы с ними**

*Необходимые данные:*
- Изображения продукции на этапах контроля.
- Логи работы оборудования (температура, вибрации, ток и пр.).
- История технического обслуживания.
- Данные о запасах, поставках, сроках выполнения заказов.
- Тайминг выполнения операций на линии.

*Методы сбора:*
- Установка промышленных датчиков (IoT).
- Камеры с высоко разрешением на линии.
- Интеграция с ERP-системой.
- API-соединения с поставщиками и логистами.

*Хранение и интеграция:*
- Локальное или облачное хранилище данных (Data Lake).
- Интеграция с MES/ERP через REST API.
- Использование ETL-пайплайнов (например, Apache NiFi, Airflow).

**5. Пошаговый план внедрения ИИ**

| Этап | Действия                          | Сроки                | Ресурсы                           | Возможные проблемы             |
| ---- | --------------------------------- | -------------------- | --------------------------------- | ------------------------------ |
| 1    | Аудит и сбор требований           | 1 месяц              | Внутр. команда, консультанты      | Неполные данные                |
| 2    | Сбор и очистка данных             | 2 месяца             | IT, инженеры                      | Несогласованность форматов     |
| 3    | Разработка MVP (пилотов)          | 3 месяца             | Data Science команда, интеграторы | Низкое качество моделей        |
| 4    | Тестирование и оценка ROI         | 1–2 месяца           | Производственный персонал         | Сопротивление изменениям       |
| 5    | Масштабирование                   | 3–6 месяцев          | Финансы, внешние подрядчики       | Простой оборудования           |
| 6    | Обучение персонала                | Параллельно          | HR, тренеры                       | Недостаток мотивации           |
| 7    | Постоянный мониторинг и улучшение | На постоянной основе | DevOps, DataOps                   | Требуется постоянная поддержка |

**6. Ожидаемые выгоды**

| Показатель               | До ИИ       | После ИИ  | Улучшение       |
| ------------------------ | ----------- | --------- | --------------- |
| Процент брака            | 3–5%        | < 1%      | -70%            |
| Простои оборудования     | 10–15 ч/мес | < 3 ч/мес | -80%            |
| Избыточные запасы        | 20%         | 5–10%     | -50%            |
| Время выполнения заказа  | 7 дней      | 4 дня     | -40%            |
| Производственные расходы | 100%        | 85–90%    | Экономия до 15% |

**7. Этические аспекты и стратегии**

*Проблемы:*
- Конфиденциальность данных: риск утечки информации о производстве.
- Предвзятость алгоритмов: особенно в системах качества.
- Прозрачность решений ИИ: «чёрный ящик» при принятии решений.

*Меры:*
- Шифрование и безопасное хранение всех данных.
- Использование объяснимого ИИ (Explainable AI) в критических задачах.
- Регулярные аудиты ИИ-моделей на предмет предвзятости.
- Разработка этического кодекса для использования ИИ на производстве.

**Заключение**

Внедрение ИИ в производственный процесс компании по выпуску бытовой электроники — это стратегически оправданный шаг, который приведёт к повышению эффективности, снижению затрат и укреплению рыночных позиций. При грамотной реализации и учёте этических рисков, ИИ станет ключевым фактором устойчивого роста компании.

*Источники*

1. Samsung: Интеграция ИИ в бытовую технику
Samsung активно внедряет ИИ в свою продукцию. Например, компания представила духовки, способные распознавать готовящуюся еду и предлагать способы её приготовления. Также холодильники оснащаются функцией распознавания хранящихся продуктов, что позволяет оптимизировать хранение и сокращать пищевые отходы
* https://vc.ru/tech/835413-samsung-vnedrit-chipy-iskusstvennogo-intellekta-vo-vsyu-svoyu-bytovuyu-tehniku-v-2024-godu
* https://www.lg.com/kz/lg-magazine/lg-buduschee-globalnogo-proizvodstva/
* https://habr.com/ru/companies/automacon/articles/810213/
* https://russian.people.com.cn/n3/2024/0918/c31518-20220230.html

2. LG: Платформа ThinQ и предиктивное обслуживание
LG использует платформу ThinQ для объединения своих умных устройств. Стиральные машины, холодильники и другие приборы оснащаются ИИ, который анализирует поведение пользователей и оптимизирует работу устройств. Кроме того, LG применяет Azure Machine Learning для предиктивного обслуживания оборудования, что позволяет выявлять и предотвращать неисправности до их возникновения .
* https://nordcloud.com/blog/10-examples-of-ai-in-manufacturing-to-inspire-your-smart-factory/?utm_source=chatgpt.com

3. Whirlpool: Умные приборы с голосовым управлением
Whirlpool внедряет ИИ в свои крупные бытовые приборы, такие как умные духовки, холодильники и стиральные машины. Эти устройства интегрированы с голосовыми помощниками, что позволяет пользователям управлять ими с помощью голосовых команд .

4. Xiaomi: Полностью автоматизированный завод
Xiaomi открыла полностью автоматизированный завод в Чанпине, который работает без участия человека 24/7. Завод производит один смартфон в секунду, используя ИИ для оптимизации производительности и устранения человеческих ошибок 
* https://www.news.com.au/finance/business/manufacturing/chinese-companys-dark-factory-will-no-human-workers-soon-be-the-norm/news-story/9468c5bc380108deba4e55a95d6c28d4

5. Philips: Роботизированное производство с ИИ
Philips использует ИИ в своём производстве электрических бритв. Завод компании в основном роботизирован, что позволяет повысить эффективность и снизить затраты. Сотрудники на месте контролируют операции и выполняют задачи, которые ИИ пока не может автоматизировать .
* https://www.netsuite.com/portal/resource/articles/erp/ai-in-manufacturing.shtml

6. Haier: Интеграция IoT и ИИ в бытовую технику
Haier активно интегрирует интернет вещей (IoT) и ИИ в свою продукцию. Компания сотрудничает с платформой IngDan для внедрения компонентов и модулей ИИ в свои умные бытовые приборы, включая системы управления голосом и анализа данных 
* https://en.wikipedia.org/wiki/Haier?utm_source=chatgpt.com



